{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37db485d-fcec-4c20-943e-239a74a70cf4",
   "metadata": {},
   "source": [
    "# Homomorphic Encrypted LeNet-1\n",
    "This notebook will show a very practical example of creating a HE-compliant model, which will be used in the notebook `HE-ML` and `HE-ML_CKKS`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1180b17e-7644-4ce8-99a6-c1906758e2eb",
   "metadata": {},
   "source": [
    "## LeNet-1\n",
    "The LeNet-1 is a small CNN developed by LeCun et al. It is composed of 5 layers: a convolutional layer with 4 kernels of size 5x5 and tanh activation, an average pooling layer with kernel of size 2, another convolutional layer with 16 kernels of size 5x5 and tanh activation, another average pooling layer with kernel of size 2, and a fully connected layers with size 192x10. \n",
    "\n",
    "The highest value in the output tensor corresponds to the label LeNet-1 associated to the input image. \n",
    "\n",
    "For this tutorial we will use the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fc122e5-a460-4a73-bed7-012b1105081b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89940a02-261f-4fc7-98e7-cea0a70be181",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fcf92dc-4929-4adc-b97e-2a1bf946bfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()\n",
    "\n",
    "train_set = torchvision.datasets.MNIST(\n",
    "    root = './data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_set = torchvision.datasets.MNIST(\n",
    "    root = './data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size=50,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set,\n",
    "    batch_size=50,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6641a660-43a4-4ed4-895a-ac7d1841dec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "\n",
    "def train_net(network, epochs, device):\n",
    "    optimizer = optim.Adam(network.parameters(), lr=0.001)\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "\n",
    "        for batch in train_loader: # Get Batch\n",
    "            images, labels = batch \n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            preds = network(images) # Pass Batch\n",
    "            loss = F.cross_entropy(preds, labels) # Calculate Loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward() # Calculate Gradients\n",
    "            optimizer.step() # Update Weights\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_correct += get_num_correct(preds, labels)\n",
    "\n",
    "        \n",
    "def test_net(network, device):\n",
    "    network.eval()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader: # Get Batch\n",
    "            images, labels = batch \n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            preds = network(images) # Pass Batch\n",
    "            loss = F.cross_entropy(preds, labels) # Calculate Loss\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_correct += get_num_correct(preds, labels)\n",
    "\n",
    "        accuracy = round(100. * (total_correct / len(test_loader.dataset)), 4)\n",
    "\n",
    "    return total_correct / len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8f74067-df4d-4b70-ae4c-ec6970c8baa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = True # If set to false, it will load models previously trained and saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03a4f779-4a5f-4a56-94c1-dba733942fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8480f18-5742-45a6-b4b7-5839b2f96763",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train:\n",
    "    accuracies = []\n",
    "    for i in range(0, experiments):\n",
    "        LeNet1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 4, kernel_size=5),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "\n",
    "            nn.Conv2d(4, 12, kernel_size=5),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "\n",
    "            nn.Flatten(),\n",
    "\n",
    "            nn.Linear(192, 10),\n",
    "        )\n",
    "        \n",
    "        LeNet1.to(device)\n",
    "        train_net(LeNet1, 15, device)\n",
    "        acc = test_net(LeNet1, device)\n",
    "        accuracies.append(acc)\n",
    "        \n",
    "    torch.save(LeNet1, \"LeNet1.pt\")\n",
    "else:\n",
    "    LeNet1 = torch.load(\"LeNet1.pt\")\n",
    "    LeNet1.eval()\n",
    "    LeNet1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19fbca30-aa89-4d74-a476-3c9107fbf851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy on test set: 0.9876\n",
      "Var: 0.0\n"
     ]
    }
   ],
   "source": [
    "m = np.array(accuracies)\n",
    "print(f\"Mean accuracy on test set: {np.mean(m)}\")\n",
    "print(f\"Var: {np.var(m)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025dfbc9-38d0-41a7-a140-9606bfeff53f",
   "metadata": {},
   "source": [
    "## Approximating\n",
    "As we know, there are some operations that cannot be performed homomorphically on encrypted values. Most notably, these operations are division and comparison. It is possible to perform only linear functions.\n",
    "\n",
    "Consequently, in the LeNet-1 scheme we used, we can not use `tanh()`. This is because we cannot apply its non-linearities.\n",
    "\n",
    "\n",
    "One of the most common approach is to replace it with a simple polynomial function, for example a square layer (which simply performs $x \\rightarrow x^2$).\n",
    "\n",
    "We define the model with all the non-linearities removed **approximated**. This model has to be re-trained, and it will be ready to be used on encrypted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52ea6449-1108-446f-ba2d-8170edcb641f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Square(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, t):\n",
    "        return torch.pow(t, 2)\n",
    "\n",
    "LeNet1_Approx = nn.Sequential(\n",
    "    nn.Conv2d(1, 4, kernel_size=5),\n",
    "    Square(),\n",
    "    nn.AvgPool2d(kernel_size=2),\n",
    "            \n",
    "    nn.Conv2d(4, 12, kernel_size=5),\n",
    "    Square(),\n",
    "    nn.AvgPool2d(kernel_size=2),\n",
    "    \n",
    "    nn.Flatten(),\n",
    "    \n",
    "    nn.Linear(192, 10),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ccaff6b-7cd5-49d2-9b5c-e8a881005fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train:\n",
    "    approx_accuracies = []\n",
    "    for i in range(0, experiments):\n",
    "        LeNet1_Approx = nn.Sequential(\n",
    "            nn.Conv2d(1, 4, kernel_size=5),\n",
    "            Square(),\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "\n",
    "            nn.Conv2d(4, 12, kernel_size=5),\n",
    "            Square(),\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "\n",
    "            nn.Flatten(),\n",
    "\n",
    "            nn.Linear(192, 10),\n",
    "        )\n",
    "        \n",
    "        LeNet1_Approx.to(device)\n",
    "        train_net(LeNet1_Approx, 15, device)\n",
    "        acc = test_net(LeNet1_Approx, device)\n",
    "        approx_accuracies.append(acc)\n",
    "        \n",
    "    torch.save(LeNet1, \"LeNet1_Approx.pt\")\n",
    "\n",
    "else:\n",
    "    LeNet1_Approx = torch.load(\"LeNet1_Approx.pt\")\n",
    "    LeNet1_Approx.eval()\n",
    "    LeNet1_Approx.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5434fcf-e01c-40c8-9ea8-bc9086e8beef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.9902\n",
      "Var: 0.0\n"
     ]
    }
   ],
   "source": [
    "m = np.array(approx_accuracies)\n",
    "print(f\"Mean: {np.mean(m)}\")\n",
    "print(f\"Var: {np.var(m)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb96de6-7053-40ce-bb88-a1532270683f",
   "metadata": {},
   "source": [
    "We can see that replacing `tanh()` with `square()` did not impact the accuracy of the model dramatically. Usually this is not the case, and approximating DL models may worsen the performance badly. This is one of the challenges that HE-ML will have to consider: the creation of DL models keeping in mind the HE constraints from the beginning.\n",
    "\n",
    "In any case, now the network is HE-compatible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5143c0-e59b-4613-bdc4-4c6bcb2666b0",
   "metadata": {},
   "source": [
    "Nonetheless, having two `square` activation can be quite heavy on your machine. We can also design and save a CNN with only a `square` activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00e2c386-3a0f-4a1d-aeec-3d6d9733e5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set (single square layer): 0.9824\n"
     ]
    }
   ],
   "source": [
    "LeNet1_Approx_singlesquare = nn.Sequential(\n",
    "    nn.Conv2d(1, 4, kernel_size=5),\n",
    "    Square(),\n",
    "    nn.AvgPool2d(kernel_size=2),\n",
    "\n",
    "    nn.Conv2d(4, 12, kernel_size=5),\n",
    "#     Square(),\n",
    "    nn.AvgPool2d(kernel_size=2),\n",
    "\n",
    "    nn.Flatten(),\n",
    "\n",
    "    nn.Linear(192, 10),\n",
    ")\n",
    "\n",
    "LeNet1_Approx_singlesquare.to(device)\n",
    "train_net(LeNet1_Approx_singlesquare, 15, device)\n",
    "acc = test_net(LeNet1_Approx_singlesquare, device)\n",
    "print(f\"Accuracy on test set (single square layer): {acc}\")\n",
    "torch.save(LeNet1_Approx_singlesquare, \"LeNet1_Approx_single_square.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33d429c-1dfb-4cb4-8e06-59091e0083c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89c04ca-3ec4-4c0a-96f1-5d82801101b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCrCNN",
   "language": "python",
   "name": "pycrcnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
